{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivanarias98/praktikumsbericht.github.io/blob/main/Kopie_von_Def_Construir_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHP5Op1wr813"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-KOrauFsC0f"
      },
      "outputs": [],
      "source": [
        "texto_original = \"\"\" \n",
        "Signed languages introduce novel challenges for\n",
        "NLP due to their visual-gestural modality, simultaneity,\n",
        "spatial coherence, and lack of written form.\n",
        "After identifying the challenges and open problems\n",
        "to successfully include signed languages in\n",
        "NLP (ยง5), we emphasize the need to: (1) develop\n",
        "a standardized tokenization method of signed languages\n",
        "with minimal information loss for its modeling;\n",
        "(2) extend core NLP technologies to signed\n",
        "languages to create linguistically-informed models;\n",
        "(3) collect signed language data of sufficient\n",
        "size that accurately represents the real world; (4) involve and collaborate with the Deaf communities\n",
        "at every step of research.\n",
        "NLP research should strive to enable a world in which\n",
        "all people, including the Deaf, have access to languages\n",
        "that fit their lived experience.\n",
        "Signed languages consist of phonological, morphological,\n",
        "syntactic, and semantic levels of structure\n",
        "that fulfill the same social, cognitive, and communicative\n",
        "purposes as other natural languages.\n",
        "Representation is a significant challenge for SLP,\n",
        "as unlike spoken languages, signed languages have\n",
        "no widely adopted written form.\n",
        "The CV community has mainly led the research\n",
        "on SLP so far to focus on processing the visual\n",
        "features in signed language videos.\n",
        "Although signed and spoken languages differ in\n",
        "modality, we argue that as both express the syntax,\n",
        "semantics, and pragmatics of natural languages,\n",
        "fundamental theories of NLP can and should be\n",
        "extended to signed languages.\n",
        "Studying signed languages can give a\n",
        "better understanding of how to model co-speech\n",
        "gestures, spatial discourse relations, and conceptual\n",
        "grounding of language through vision.\n",
        "Data is essential to develop any of the core NLP\n",
        "tools previously described, and current efforts in\n",
        "SLP are often limited by the lack of adequate data.\n",
        "We believe that the NLP community is wellpositioned,\n",
        "especially with the plethora of successful\n",
        "spoken language processing methods coupled\n",
        "with the recent advent of computer vision tools\n",
        "for videos, to bring the linguistic insight needed\n",
        "for better signed language models.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "ionijXW_sG1Q",
        "outputId": "0414ec2c-73c8-42ab-943e-91525156cdb6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' \\nSigned languages introduce novel challenges for\\nNLP due to their visual-gestural modality, simultaneity,\\nspatial coherence, and lack of written form.\\nAfter identifying the challenges and open problems\\nto successfully include signed languages in\\nNLP (ยง5), we emphasize the need to: (1) develop\\na standardized tokenization method of signed languages\\nwith minimal information loss for its modeling;\\n(2) extend core NLP technologies to signed\\nlanguages to create linguistically-informed models;\\n(3) collect signed language data of sufficient\\nsize that accurately represents the real world; (4) involve and collaborate with the Deaf communities\\nat every step of research.\\nNLP research should strive to enable a world in which\\nall people, including the Deaf, have access to languages\\nthat fit their lived experience.\\nSigned languages consist of phonological, morphological,\\nsyntactic, and semantic levels of structure\\nthat fulfill the same social, cognitive, and communicative\\npurposes as other natural languages.\\nRepresentation is a significant challenge for SLP,\\nas unlike spoken languages, signed languages have\\nno widely adopted written form.\\nThe CV community has mainly led the research\\non SLP so far to focus on processing the visual\\nfeatures in signed language videos.\\nAlthough signed and spoken languages differ in\\nmodality, we argue that as both express the syntax,\\nsemantics, and pragmatics of natural languages,\\nfundamental theories of NLP can and should be\\nextended to signed languages.\\nStudying signed languages can give a\\nbetter understanding of how to model co-speech\\ngestures, spatial discourse relations, and conceptual\\ngrounding of language through vision.\\nData is essential to develop any of the core NLP\\ntools previously described, and current efforts in\\nSLP are often limited by the lack of adequate data.\\nWe believe that the NLP community is wellpositioned,\\nespecially with the plethora of successful\\nspoken language processing methods coupled\\nwith the recent advent of computer vision tools\\nfor videos, to bring the linguistic insight needed\\nfor better signed language models.\\n\\n'"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texto_original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQc0ou8kuSQh"
      },
      "outputs": [],
      "source": [
        "texto_original = re.sub(r'\\s+', ' ', texto_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "Rm7nuFX9uY4i",
        "outputId": "370bb79a-6e53-4c72-f403-e7868a88097e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Signed languages introduce novel challenges for NLP due to their visual-gestural modality, simultaneity, spatial coherence, and lack of written form. After identifying the challenges and open problems to successfully include signed languages in NLP (ยง5), we emphasize the need to: (1) develop a standardized tokenization method of signed languages with minimal information loss for its modeling; (2) extend core NLP technologies to signed languages to create linguistically-informed models; (3) collect signed language data of sufficient size that accurately represents the real world; (4) involve and collaborate with the Deaf communities at every step of research. NLP research should strive to enable a world in which all people, including the Deaf, have access to languages that fit their lived experience. Signed languages consist of phonological, morphological, syntactic, and semantic levels of structure that fulfill the same social, cognitive, and communicative purposes as other natural languages. Representation is a significant challenge for SLP, as unlike spoken languages, signed languages have no widely adopted written form. The CV community has mainly led the research on SLP so far to focus on processing the visual features in signed language videos. Although signed and spoken languages differ in modality, we argue that as both express the syntax, semantics, and pragmatics of natural languages, fundamental theories of NLP can and should be extended to signed languages. Studying signed languages can give a better understanding of how to model co-speech gestures, spatial discourse relations, and conceptual grounding of language through vision. Data is essential to develop any of the core NLP tools previously described, and current efforts in SLP are often limited by the lack of adequate data. We believe that the NLP community is wellpositioned, especially with the plethora of successful spoken language processing methods coupled with the recent advent of computer vision tools for videos, to bring the linguistic insight needed for better signed language models. '"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texto_original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT5pj-9Sp78f",
        "outputId": "49f9b713-23a8-4985-c3a5-ab9034f4c2c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textstat in /usr/local/lib/python3.7/dist-packages (0.7.2)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.7/dist-packages (from textstat) (0.11.0)\n"
          ]
        }
      ],
      "source": [
        "#Textstat is an easy to use library to calculate statistics from text. It helps determine readability, complexity, and grade level.\n",
        "!pip install textstat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAyvlLU7qEh3"
      },
      "outputs": [],
      "source": [
        "import textstat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HUdq6ogqH_v"
      },
      "outputs": [],
      "source": [
        "textstat.set_lang(\"en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox19dVT1uKbh",
        "outputId": "7e50422d-b849-4587-d002-a807f089abba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sentence count\n",
        "textstat.sentence_count(texto_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KGrwpxwuy4d",
        "outputId": "9e9374ad-e9d2-4b01-c9d7-7e5518fef965"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31.1"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#avg_sentence_length\n",
        "textstat.avg_sentence_length(texto_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqmZJYJVushV",
        "outputId": "70b779e2-21a6-4f2b-f6b1-2ad7e4ca1035"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "311"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lexicon count\n",
        "textstat.lexicon_count(texto_original, removepunct=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQZvQhA4u6D-",
        "outputId": "cbbae13d-0e9d-4f81-bdbd-f90ff41a7e2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.58"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#avg_letter_per_word\n",
        "textstat.avg_letter_per_word(texto_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX_Sabk95AUD",
        "outputId": "dfdc1e69-b362-44d6-bc0c-849f3f182ca7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31.45"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Flesch Reading Ease formula\n",
        "# The Flesch Reading Ease formula - Returns the Flesch Reading Ease Score.\n",
        "## While the maximum score is 121.22, there is no limit on how low the score can be. A negative score is valid. Around 65 means this text has a \"standard\" difficuly to be read.\n",
        "## In the Flesch reading-ease test, higher scores indicate material that is easier to read; lower numbers mark passages that are more difficult to read. \n",
        "## One sentence in the beginning of Swann's Way, by Marcel Proust, has a score of โ515.1. https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#cite_note-11\n",
        "textstat.flesch_reading_ease(texto_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myvMLWLXvGSI",
        "outputId": "82e93e5e-62d5-4cb2-83a8-b994e96ec3bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "26.19"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Time to read the text in seconds\n",
        "textstat.reading_time(texto_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoP4ex87Az6L",
        "outputId": "7f498db3-e805-4576-d1c6-1831c436bad0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "97"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "textstat.difficult_words(texto_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMp0vVQyvN0I",
        "outputId": "8961b92e-e52d-4ee7-a55f-7c3bff51fcc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['processing',\n",
              " 'statistical',\n",
              " 'subtext',\n",
              " 'discussed',\n",
              " 'students',\n",
              " 'professor',\n",
              " 'perspectives',\n",
              " 'arguments',\n",
              " 'human',\n",
              " 'grounding',\n",
              " 'decision',\n",
              " 'including',\n",
              " 'assumptions',\n",
              " 'finding',\n",
              " 'relies',\n",
              " 'methods',\n",
              " 'experiences',\n",
              " \"goldwasser's\",\n",
              " 'traditional',\n",
              " 'online',\n",
              " 'motivation',\n",
              " 'vital',\n",
              " 'techniques',\n",
              " 'articles',\n",
              " 'languages',\n",
              " 'artificial',\n",
              " 'discuss',\n",
              " 'twitter',\n",
              " 'developing',\n",
              " 'members',\n",
              " 'meaning',\n",
              " 'conceptualize',\n",
              " 'analyze',\n",
              " 'describing',\n",
              " 'emphasizes',\n",
              " 'currents',\n",
              " 'processes',\n",
              " 'requires',\n",
              " 'thousands',\n",
              " 'internet',\n",
              " 'computers',\n",
              " 'connecting',\n",
              " 'society',\n",
              " 'solutions',\n",
              " 'expressed',\n",
              " 'progress',\n",
              " 'goldwasser',\n",
              " 'combined',\n",
              " 'individual',\n",
              " 'university',\n",
              " 'speakers',\n",
              " 'underlying',\n",
              " 'subfield',\n",
              " 'challenge',\n",
              " 'asking',\n",
              " 'technical',\n",
              " 'shorthand',\n",
              " 'knowing',\n",
              " 'incorporating',\n",
              " 'decisions',\n",
              " 'intelligence',\n",
              " 'natural',\n",
              " 'considerations',\n",
              " 'science',\n",
              " 'social',\n",
              " 'issues',\n",
              " 'readers',\n",
              " 'flourishing',\n",
              " 'discourse',\n",
              " 'manner',\n",
              " 'broader',\n",
              " 'interpret',\n",
              " 'fluent',\n",
              " 'whether',\n",
              " 'scenarios',\n",
              " 'studies',\n",
              " 'wisdom',\n",
              " 'associate',\n",
              " 'distilled',\n",
              " 'deeper',\n",
              " 'media',\n",
              " 'model',\n",
              " 'understanding',\n",
              " 'connection',\n",
              " 'crucial',\n",
              " 'translate',\n",
              " 'represent',\n",
              " 'unbiased',\n",
              " 'humans',\n",
              " 'legislative',\n",
              " 'operationalizing',\n",
              " 'computational',\n",
              " 'journalist',\n",
              " 'context',\n",
              " 'communication',\n",
              " 'computer']"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# difficult words\n",
        "textstat.difficult_words_list(texto_original) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x8zev0x2Ir6",
        "outputId": "ef2183c0-7c6a-423e-90cf-4c77da1021dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lexicalrichness\n",
            "  Downloading lexicalrichness-0.1.4.tar.gz (18 kB)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from lexicalrichness) (1.4.1)\n",
            "Requirement already satisfied: textblob>=0.15.3 in /usr/local/lib/python3.7/dist-packages (from lexicalrichness) (0.15.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=1.0.0->lexicalrichness) (1.19.5)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob>=0.15.3->lexicalrichness) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob>=0.15.3->lexicalrichness) (1.15.0)\n",
            "Building wheels for collected packages: lexicalrichness\n",
            "  Building wheel for lexicalrichness (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lexicalrichness: filename=lexicalrichness-0.1.4-py2.py3-none-any.whl size=10111 sha256=213b00d3a54c07ef5839799422b93435425edd364e3fd7deb3b5dcc21a135fe6\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/53/09/ce0a119b59493ae5be4e9773457df832bbce66d926fce1d043\n",
            "Successfully built lexicalrichness\n",
            "Installing collected packages: lexicalrichness\n",
            "Successfully installed lexicalrichness-0.1.4\n"
          ]
        }
      ],
      "source": [
        "pip install lexicalrichness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByVrgGt529QQ"
      },
      "outputs": [],
      "source": [
        "from lexicalrichness import LexicalRichness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkN46hvD2kD9"
      },
      "outputs": [],
      "source": [
        "lex = LexicalRichness(texto_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjZQw-Nb3dde",
        "outputId": "640af7b6-55ad-4c42-c562-0b0bd4d2aaea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "243"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Return (unique) word count.\n",
        ">>> lex.terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOz44K2W3k9v",
        "outputId": "bd791124-fb55-4466-861c-7b238f7baf20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5570032573289903"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Return type-token ratio (TTR) of text.\n",
        ">>> lex.ttr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev6udsyb_9I0",
        "outputId": "f17268ec-78d2-46cb-afd5-b17eff2d5e6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57.07828490208465"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Return Measure of Textual Lexical Diversity (MTLD).\n",
        ">>> lex.mtld(threshold=0.72)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UqHyKHlB1aG",
        "outputId": "c4b0ec75-926d-4aaf-bc59-0972bdc92bec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment(polarity=0.12138752052545157, subjectivity=0.46124794745484404)\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "\n",
        "blob_text = TextBlob(texto_original)\n",
        "print(blob_text.sentiment)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Kopie von Def_Construir datasets.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}